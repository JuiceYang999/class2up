## **任务七：大数据分析与可视化（设备状态预测）**

此任务的目标是利用机器学习或深度学习算法，分析我们采集到的数据，预测设备状态，并将分析结果集成到我们的VUE网页中。

-----

### ⚠️ 重要说明：缺失的先决条件

《项目课程2025.pdf》中提到“根据提供的数据集，选择合适的深度学习/机器学习算法，训练模型”。

在您上传的文件中，**并未包含这个“数据集”或已经“训练好的模型文件”**（例如 `.pkl` 或 `.h5` 文件）。

因此，本指南将为您提供一个**完整的框架**。您需要按照本指南的假设，准备一个模型文件。

-----

### 7.1 准备工作（主机操作）

#### 7.1.1 安装 Python 依赖库

我们需要用于机器学习的库。当您回到主机时，请在**终端 5**（运行后端的终端）中，`cd` 到 VUE 项目根目录，并执行：

```bash
pip install scikit-learn joblib numpy
```

  * `scikit-learn`: 用于加载和运行模型。
  * `joblib`: 用于加载/保存 `.pkl` 格式的模型文件。
  * `numpy`: 几乎所有ML模型都依赖它进行数据处理。

#### 7.1.2 准备模型文件（占位符）

您需要一个**预先训练好**的模型文件。由于我们没有真实模型，请按以下步骤**创建一个模拟的占位符模型**：

1.  在您的 `pyt/` 文件夹中，**新建**一个 `_create_dummy_model.py` 文件（带下划线以示区别）。

2.  将以下代码复制进去：

    ```python
    import joblib
    import numpy as np
    from sklearn.ensemble import RandomForestClassifier

    # 1. 创建一个简单的“假”模型
    # 假设模型输入是50个数据点 (DATA_WINDOW_SIZE)
    # 假设 0 = 正常, 1 = 故障
    X_train = np.random.rand(10, 50) # 10个样本，每个50个特征
    y_train = [0, 0, 0, 0, 1, 0, 0, 0, 0, 1] # 10个标签

    model = RandomForestClassifier()
    model.fit(X_train, y_train)

    # 2. 将模型保存到文件
    MODEL_PATH = 'status_predictor.pkl'
    joblib.dump(model, MODEL_PATH)

    print(f"模拟模型已创建并保存到: {MODEL_PATH}")
    print("请将此文件放在 'pyt/' 文件夹下（如果它不在的话）。")

    # 3. 测试加载
    loaded_model = joblib.load(MODEL_PATH)
    test_data = np.random.rand(1, 50)
    prediction = loaded_model.predict(test_data)
    print(f"模型加载测试成功，预测结果: {prediction}")
    ```

3.  在**终端 5**中，`cd` 到 `pyt` 文件夹，并运行它：

    ```bash
    cd pyt
    python _create_dummy_model.py
    ```

4.  **验证：** 运行成功后，您的 `pyt` 文件夹中现在应该有了一个 `status_predictor.pkl` 文件。这就是我们将要集成的模型。

-----

### 7.2 后端 (Python) 代码最终更新

我们需要再次更新 `backend.py`。这次的改动至关重要：

1.  **加载模型：** 在启动时加载 `status_predictor.pkl`。
2.  **数据窗口：** 修改 `handle_message`，不再只存 *最新值*，而是存储一个包含**最近50个数据点**的列表（数据窗口），因为模型需要一个数据窗口来进行分析。
3.  **新建 `/predict/` 接口：** 创建一个新的 API 接口，用于接收分析请求，提取特征（占位），运行模型，并返回预测结果。

请**替换** `pyt/backend.py` 文件的**全部内容**为以下**最终版本**：

**文件路径：** `juiceyang999/class2up/class2up-9730b2fcdf474be54786a1f787cc6b005a26d2fc/pyt/backend.py`

```python
from flask import Flask, request, jsonify
from flask_cors import CORS
from flask_mqtt import Mqtt
import json
import pymysql
import datetime
from influxdb_client import InfluxDBClient, Point, WritePrecision
from influxdb_client.client.write_api import SYNCHRONOUS
import requests
import atexit

# (新增) 引入 ML 库
import joblib
import numpy as np

# --- 数据库配置 (保持不变) ---
MYSQL_HOST = 'localhost'
MYSQL_USER = 'root'
MYSQL_PASSWORD = 'xjtu2025'  # ！！！请修改为您的MySQL密码！！！
MYSQL_DB = 'mqtt_data'
MYSQL_PORT = 3306

INFLUX_URL = "http://localhost:8086"
INFLUX_TOKEN = "YOUR_API_TOKEN_HERE"  # ！！！请修改为您复制的 Token！！！
INFLUX_ORG = "my-org"
INFLUX_BUCKET = "mqtt_bucket"

# --- HDFS 平台配置 (占位符) ---
HDFS_WEB_API_URL = "http://YOUR_HADOOP_HOST:9870/webhdfs/v1"
HDFS_TARGET_PATH = "/user/your_name/machine_data.csv"
HDFS_USER = "your_username"

# --- (新增) ML 模型配置 ---
MODEL_PATH = 'pyt/status_predictor.pkl' # 假设模型在pyt目录下
DATA_WINDOW_SIZE = 50 # 假设模型需要50个数据点作为输入
model = None

try:
    # 1. (新增) 在启动时加载模型
    model = joblib.load(MODEL_PATH)
    print(f"机器学习模型 {MODEL_PATH} 加载成功。")
except FileNotFoundError:
    print(f"警告：模型文件 {MODEL_PATH} 未找到。分析功能将不可用。")
    print("请先运行 _create_dummy_model.py 来创建一个模拟模型。")
except Exception as e:
    print(f"模型加载失败: {e}")
# -------------------------

# 初始化 InfluxDB
try:
    influx_client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG)
    write_api = influx_client.write_api(write_options=SYNCHRONOUS)
    print("InfluxDB 客户端初始化成功。")
except Exception as e:
    print(f"InfluxDB 客户端初始化失败: {e}")

# HDFS 本地临时文件
local_temp_file_path = "hdfs_temp_data.csv"
local_file = None
try:
    local_file = open(local_temp_file_path, "a", encoding="utf-8")
    if local_file.tell() == 0:
        local_file.write("timestamp,data_id,value\n")
    print(f"打开本地临时文件 {local_temp_file_path} 成功。")
except Exception as e:
    print(f"打开本地临时文件失败: {e}")

# 注册 HDFS 退出时上传
@atexit.register
def upload_to_hdfs_on_exit():
    global local_file
    if local_file:
        local_file.close()
        print(f"程序退出，正在将 {local_temp_file_path} 上传到 HDFS...")
        try:
            create_url = f"{HDFS_WEB_API_URL}{HDFS_TARGET_PATH}?op=CREATE&overwrite=true&user.name={HDFS_USER}"
            r_create = requests.put(create_url, allow_redirects=False)
            if r_create.status_code == 307:
                data_node_url = r_create.headers['Location']
                with open(local_temp_file_path, "rb") as f:
                    r_upload = requests.put(data_node_url, data=f)
                    if r_upload.status_code == 201:
                        print(f"HDFS 文件上传成功: {HDFS_TARGET_PATH}")
                    else:
                        print(f"HDFS 文件上传失败: {r_upload.status_code} - {r_upload.text}")
            else:
                 print(f"HDFS 'CREATE' 请求失败: {r_create.status_code} - {r_create.text}")
        except Exception as e:
            print(f"HDFS 上传时发生严重错误: {e}")

# --- Flask 和 MQTT 初始化 ---
app = Flask(__name__)
CORS(app)
app.config['MQTT_BROKER_URL'] = '127.0.0.1'
app.config['MQTT_BROKER_PORT'] = 1883
app.config['MQTT_CLIENT_ID'] = 'flask_mqtt_client'
mqtt = Mqtt(app)

# --- (重大更新) 数据存储 ---
# 我们需要一个地方存Echarts的最新值，一个地方存模型的数据窗口
latest_data_store = {} # 供 Echarts 使用 (最新值)
data_window_store = {} # 供 ML 模型使用 (数据窗口)
# ---------------------------

# --- 数据库写入函数 (保持不变) ---
def save_to_mysql(data_id, value, time_str):
    conn = None
    cur = None
    try:
        conn = pymysql.connect(host=MYSQL_HOST, user=MYSQL_USER, password=MYSQL_PASSWORD, database=MYSQL_DB, port=MYSQL_PORT, charset='utf8')
        cur = conn.cursor()
        sql = "INSERT INTO mac_data (data_id, payload, time) VALUES (%s, %s, %s)"
        cur.execute(sql, (data_id, str(value), time_str))
        conn.commit()
        print(f"MySQL 写入成功: ID={data_id}, Value={value}")
    except Exception as e:
        print(f"MySQL 写入失败: {e}")
    finally:
        if cur: cur.close()
        if conn: conn.close()

def save_to_influxdb(data_id, value, time_obj):
    try:
        value_float = float(value)
        p = Point("machine_data").tag("device_id", "STRESS_TEST_00000").tag("data_id", data_id).field("value", value_float).time(time_obj, WritePrecision.NS)
        write_api.write(bucket=INFLUX_BUCKET, org=INFLUX_ORG, record=p)
        print(f"InfluxDB 写入成功: ID={data_id}, Value={value_float}")
    except Exception as e:
        print(f"InfluxDB 写入失败: {e}")

def save_to_distributed_platform(data_id, value, time_obj):
    global local_file
    if local_file:
        try:
            time_iso = time_obj.isoformat()
            line = f"{time_iso},{data_id},{value}\n"
            local_file.write(line)
            local_file.flush()
        except Exception as e:
            print(f"本地临时文件写入失败: {e}")

# --- MQTT 回调 (更新) ---
@mqtt.on_connect()
def handle_connect(client, userdata, flags, rc):
    if rc == 0:
        print("MQTT 连接成功 (rc=0)")
        response_topic = "Query/Response/STRESS_TEST_00000"
        mqtt.subscribe(response_topic)
        print(f"已自动订阅主题: {response_topic}")
    else:
        print(f"MQTT 连接失败，返回码: {rc}")

@mqtt.on_message()
def handle_message(client, userdata, message):
    try:
        payload_str = message.payload.decode()
        data = json.loads(payload_str)
        
        time_now_utc = datetime.datetime.utcnow()
        time_now_local_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        if 'values' in data and isinstance(data['values'], list):
            for item in data['values']:
                if 'id' in item and 'values' in item:
                    data_id = item['id']
                    value = item['values'][0]
                    
                    # 1. 暂存 (供 Echarts)
                    latest_data_store[data_id] = value

                    # 2. (新增) 存储数据窗口 (供 ML)
                    if data_id not in data_window_store:
                        data_window_store[data_id] = []
                    
                    data_window_store[data_id].append(float(value)) # 存为浮点数
                    
                    # 保持窗口大小
                    if len(data_window_store[data_id]) > DATA_WINDOW_SIZE:
                        data_window_store[data_id].pop(0) # 移除最旧的数据

                    # 3. 写入 MySQL
                    save_to_mysql(data_id, value, time_now_local_str)
                    
                    # 4. 写入 InfluxDB
                    save_to_influxdb(data_id, value, time_now_utc)
                    
                    # 5. 写入 HDFS 缓存
                    save_to_distributed_platform(data_id, value, time_now_utc)
            
    except Exception as e:
        print(f"处理消息失败: {e}")

# --- Flask API 路由 (新增 /predict/ 接口) ---
@app.route('/connect/', methods=['POST', 'GET'])
def make_connect():
    # ... (此函数保持不变) ...
    try:
        data_connect = request.get_json()['data']
        app.config['MQTT_BROKER_URL'] = data_connect['host']
        app.config['MQTT_BROKER_PORT'] = data_connect['port']
        app.config['MQTT_CLIENT_ID'] = data_connect['clientid']
        if mqtt.client.is_connected():
            mqtt.client.disconnect()
        mqtt.client.username_pw_set(None, None)
        mqtt.client._client_id = data_connect['clientid'].encode()
        mqtt.client.reinitialise()
        mqtt.client.connect(data_connect['host'], data_connect['port'])
        return jsonify({'rc_status': 'success'})
    except Exception as e:
        return jsonify({'rc_status': str(e)})

@app.route('/publish/', methods=['POST'])
def do_publish():
    # ... (此函数保持不变) ...
    try:
        data = request.get_json()
        topic = data.get('topic')
        payload = data.get('payload', "{}")
        mqtt.publish(topic, payload)
        return jsonify({'status': 'published', 'topic': topic})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/get_data/', methods=['POST'])
def get_data():
    # ... (此函数保持不变) ...
    try:
        data = request.get_json()
        data_id = data.get('id')
        value = latest_data_store.get(data_id) # 从 'latest_data_store' 获取
        if value is not None:
            return jsonify({'status': 'ok', 'id': data_id, 'value': value})
        else:
            return jsonify({'status': 'not_found', 'id': data_id, 'value': None})
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

# 2. (新增) 预测 API 接口
@app.route('/predict/', methods=['POST'])
def predict_status():
    global model
    if model is None:
        return jsonify({'status': 'error', 'message': '模型未加载，请检查 status_predictor.pkl 文件'}), 500
    
    try:
        data = request.get_json()
        data_id = data.get('id') # 例如 '0103502202'
        
        # 1. 获取数据窗口
        window_data = data_window_store.get(data_id)
        
        # 检查数据是否足够
        if not window_data or len(window_data) < DATA_WINDOW_SIZE:
            return jsonify({
                'status': 'wait', 
                'message': f'数据采集中，当前 {len(window_data) if window_data else 0}/{DATA_WINDOW_SIZE} 点，请稍候...'
            })
        
        # 2. (占位符) 特征工程
        # ！！！真实场景中，您需要在此处进行与训练时完全一致的特征提取
        # 例如: features = [np.mean(window_data), np.std(window_data), np.max(window_data), ...]
        # 为保持示例简洁，我们假设模型可以直接使用这50个点
        features_vector = np.array(window_data).reshape(1, -1) # 转换成 (1, 50) 的形状
        
        # 3. 模型预测
        prediction_code = model.predict(features_vector)
        
        # 4. 转换预测结果 (与 _create_dummy_model.py 中的 0 和 1 对应)
        status_map = {0: '设备状态正常', 1: '设备故障预警'}
        prediction_text = status_map.get(prediction_code[0], '未知状态')
        
        return jsonify({'status': 'ok', 'prediction': prediction_text})

    except Exception as e:
        print(f"预测失败: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

# 启动 Flask 服务
if __name__ == '__main__':
    # debug=True 模式下，文件更改会自动重启服务。
    # 但 ate_exit 可能会在自动重载时被触发，
    # 在生产环境中请使用 debug=False
    app.run(debug=True, host='127.0.0.1', port=5000)

```

-----

### 7.4 前端 (VUE) `DataProcess.vue` 界面编写

现在我们来编写**任务7**对应的VUE页面。我们在任务2中创建了 `DataProcess.vue` 文件，现在来填充它。

请**替换** `src/components/DataProcess.vue` 文件的**全部内容**为以下代码：

**文件路径：** `juiceyang999/class2up/class2up-9730b2fcdf474be54786a1f787cc6b005a26d2fc/src/components/DataProcess.vue`

```vue
<template>
  <el-container>
    <el-header><h2>数据分析与设备预测</h2></el-header>
    <el-main>
      <el-card class="box-card">
        <div slot="header">
          <span>X轴设备状态实时预测</span>
          <p style="font-size: 12px; color: #909399; margin: 0;">
            基于后台 'status_predictor.pkl' 模型进行预测
          </p>
        </div>
        
        <el-form label-width="120px">
          <el-form-item label="分析数据ID:">
            <el-input v-model="dataIdToAnalyze" readonly></el-input>
          </el-form-item>
          <el-form-item>
            <el-button 
              type="primary" 
              @click="runAnalysis" 
              :loading="isLoading" 
              style="width: 100%;"
            >
              {{ isLoading ? '分析中...' : '运行状态分析' }}
            </el-button>
          </el-form-item>
        </el-form>
        
        <el-alert
          v-if="analysisResult.message"
          :title="analysisResult.title"
          :type="analysisResult.type"
          :description="analysisResult.message"
          show-icon
          :closable="false"
          style="margin-top: 20px;"
        >
        </el-alert>
      </el-card>
    </el-main>
  </el-container>
</template>

<script>
import axios from "axios";
axios.defaults.baseURL = "/api";

export default {
  name: "DataProcess",
  data() {
    return {
      // 我们分析 'X轴实际速度' (ID 0103502202)
      dataIdToAnalyze: '0103502202', 
      isLoading: false,
      // 存储分析结果
      analysisResult: {
        title: '等待分析',
        type: 'info', // 'success' (正常), 'warning' (等待), 'error' (故障/失败)
        message: '点击按钮开始实时分析。模型需要50个数据点，请确保数据显示页面已运行片刻。'
      }
    };
  },
  methods: {
    // 3. 运行分析的方法
    runAnalysis() {
      this.isLoading = true;
      this.analysisResult.message = '正在从后端获取数据并调用模型...';
      this.analysisResult.type = 'info';
      this.analysisResult.title = '分析中';

      // 4. 调用后端的 /predict/ 接口
      axios.post("/predict/", { id: this.dataIdToAnalyze })
        .then(res => {
          this.isLoading = false;
          const data = res.data;
          
          if (data.status === 'ok') {
            // 5. 根据预测结果更新UI
            // (对应 backend.py 中的 "设备状态正常" 或 "设备故障预警")
            this.analysisResult.type = data.prediction.includes('正常') ? 'success' : 'error';
            this.analysisResult.title = `分析完成: ${data.prediction}`;
            this.analysisResult.message = `模型预测结果: ${data.prediction} (数据时间: ${new Date().toLocaleTimeString()})`;
          
          } else if (data.status === 'wait') {
            // 6. 处理数据不足的情况
            this.analysisResult.type = 'warning';
            this.analysisResult.title = '数据不足';
            this.analysisResult.message = data.message; // 显示后端传来的等待消息
          
          } else {
            // 7. 处理其他错误
            this.analysisResult.type = 'error';
            this.analysisResult.title = '分析失败';
            this.analysisResult.message = data.message;
          }
        })
        .catch(err => {
          // 8. 处理网络或后端服务错误
          this.isLoading = false;
          this.analysisResult.type = 'error';
          this.analysisResult.title = '请求失败';
          this.analysisResult.message = '无法连接到后端 /predict/ 接口: ' + (err.response ? err.response.data.message : err.message);
        });
    }
  }
};
</script>

<style scoped>
.el-header {
  background-color: #b3c0d1;
  color: #333;
  line-height: 60px;
}
.box-card {
  width: 60%;
  margin: 0 auto; /* 居中显示 */
  text-align: left;
}
</style>
```

-----

### 7.5 运行与调试（当您回到主机时）

1.  **启动所有 5 个终端**（同任务六）。
2.  **测试：**
      * 打开浏览器访问 VUE 页面（如 `http://localhost:8080`）。
      * **步骤 1:** 点击 “**数据采集**” 页面，点击 “**连接**”，确保连接成功。
      * **步骤 2:** 点击 “**数据显示**” 页面，**等待至少 2-3 分钟**。
          * **原因：** 我们的后端需要收集 `DATA_WINDOW_SIZE = 50` 个数据点（每3秒1个），才能让模型进行预测。
      * **步骤 3:** 点击 “**数据分析**” 页面。
      * **步骤 4:** 点击 “**运行状态分析**” 按钮。
      * **预期结果：**
          * **如果数据不足：** 您会看到一个**黄色**的警告框，提示 “数据采集中，当前.../50 点...”。
          * **如果数据充足：** 您会看到一个**绿色**（正常）或**红色**（故障预警）的提示框，显示“分析完成: 设备状态正常”或“分析完成: 设备故障预警”。
          * 在 **终端 5** (Python 后端) 中，您会看到 `features_vector...` 和 `prediction...` 相关的打印信息。

**任务七完成**。您已成功构建了一个完整的数据采集、存储、可视化，并集成了机器学习预测模型的 VUE + Python 系统，全面达到了《大数据部分项目指导书》 和《项目课程2025.pdf》 的所有核心要求。